{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FU9YdmfuROkd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "# import pyaudio #마이크를 사용하기 위한 라이브러리\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZE33onQnELr"
   },
   "outputs": [],
   "source": [
    "##### 변수 설정 부분 #####\n",
    "# FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100 #비트레이트 설정\n",
    "CHUNK = int(RATE / 10) # 버퍼 사이즈 1초당 44100비트레이트 이므로 100ms단위\n",
    "RECORD_SECONDS = 5 #녹음할 시간 설정\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "DATA_PATH = (\"./data/\")\n",
    "X_train = []#train_data 저장할 공간\n",
    "X_test = []\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "tf_classes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSetyRMsnP__"
   },
   "outputs": [],
   "source": [
    "def load_wave_generator(path): \n",
    "       \n",
    "    batch_waves = []\n",
    "    labels = []\n",
    "    X_data = []\n",
    "    Y_label = []    \n",
    "    global X_train, X_test, Y_train, Y_test, tf_classes\n",
    "    \n",
    "    folders = os.listdir(path)\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(path):continue #폴더가 아니면 continue                   \n",
    "        files = os.listdir(path+\"/\"+folder)        \n",
    "        print(\"Foldername :\",folder,\"-\",len(files),\"파일\")\n",
    "        #폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "        for wav in files:\n",
    "            if not wav.endswith(\".wav\"):continue\n",
    "            else:               \n",
    "                #print(\"Filename :\",wav)#.wav 파일이 아니면 continue\n",
    "                y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "              \n",
    "                X_data.extend(mfcc)\n",
    "               # print(len(mfcc))\n",
    "                \n",
    "                label = [0 for i in range(len(folders))]\n",
    "                label[tf_classes] = 1\n",
    "                \n",
    "                for i in range(len(mfcc)):\n",
    "                    Y_label.append(label)\n",
    "                #print(Y_label)\n",
    "        tf_classes = tf_classes+1\n",
    "    #end loop\n",
    "    print(\"X_data :\",np.shape(X_data))\n",
    "    print(\"Y_label :\",np.shape(Y_label))\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(np.array(X_data), np.array(Y_label))\n",
    "\n",
    "    xy = (X_train, X_test, Y_train, Y_test)\n",
    "    np.save(\"./data.npy\",xy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251.0
    },
    "colab_type": "code",
    "id": "0LZUxL0xROkr",
    "outputId": "3cfceda4-224d-4b4c-927e-acd715c3320f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername : 0 - 20 파일\n",
      "Foldername : 1 - 20 파일\n",
      "Foldername : 2 - 20 파일\n",
      "Foldername : 3 - 20 파일\n",
      "Foldername : 4 - 20 파일\n",
      "Foldername : 5 - 21 파일\n",
      "X_data : (60742, 13)\n",
      "Y_label : (60742, 6)\n",
      "6 개의 클래스\n",
      "X_train : (45556, 13)\n",
      "Y_train : (45556, 6)\n",
      "X_test : (15186, 13)\n",
      "Y_test : (15186, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "load_wave_generator(DATA_PATH)\n",
    "\n",
    "print(tf_classes,\"개의 클래스\")\n",
    "print(\"X_train :\",np.shape(X_train))\n",
    "print(\"Y_train :\",np.shape(Y_train))\n",
    "print(\"X_test :\",np.shape(X_test))\n",
    "print(\"Y_test :\",np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "colab_type": "code",
    "id": "neHIhweMROkt",
    "outputId": "2e1bc0fa-70b8-4ea9-a986-ff3b4fc28450",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\pjt\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f51b647f2d>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f51b647f2d>:103: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-7-a9f51b647f2d>:108: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n",
      "Epoch: 0000 cost = 2.186643243\n",
      "Epoch: 0001 cost = 1.908542514\n",
      "Epoch: 0002 cost = 1.861475527\n",
      "Epoch: 0003 cost = 1.841903210\n",
      "Epoch: 0004 cost = 1.831267834\n",
      "Epoch: 0005 cost = 1.822090745\n",
      "Epoch: 0006 cost = 1.817279696\n",
      "Epoch: 0007 cost = 1.812623560\n",
      "Epoch: 0008 cost = 1.811272681\n",
      "Epoch: 0009 cost = 1.808108747\n",
      "Epoch: 0010 cost = 1.806651056\n",
      "Epoch: 0011 cost = 1.802310944\n",
      "Epoch: 0012 cost = 1.801233113\n",
      "Epoch: 0013 cost = 1.795049489\n",
      "Epoch: 0014 cost = 1.794782102\n",
      "Epoch: 0015 cost = 1.790380418\n",
      "Epoch: 0016 cost = 1.783433437\n",
      "Epoch: 0017 cost = 1.779043913\n",
      "Epoch: 0018 cost = 1.771037877\n",
      "Epoch: 0019 cost = 1.761558473\n",
      "Epoch: 0020 cost = 1.751638770\n",
      "Epoch: 0021 cost = 1.740805864\n",
      "Epoch: 0022 cost = 1.726879776\n",
      "Epoch: 0023 cost = 1.713195384\n",
      "Epoch: 0024 cost = 1.699930847\n",
      "Epoch: 0025 cost = 1.688247144\n",
      "Epoch: 0026 cost = 1.677334964\n",
      "Epoch: 0027 cost = 1.662656426\n",
      "Epoch: 0028 cost = 1.644641340\n",
      "Epoch: 0029 cost = 1.631333411\n",
      "Epoch: 0030 cost = 1.612515867\n",
      "Epoch: 0031 cost = 1.598425984\n",
      "Epoch: 0032 cost = 1.583031535\n",
      "Epoch: 0033 cost = 1.564669251\n",
      "Epoch: 0034 cost = 1.546453059\n",
      "Epoch: 0035 cost = 1.529368460\n",
      "Epoch: 0036 cost = 1.511327565\n",
      "Epoch: 0037 cost = 1.493425250\n",
      "Epoch: 0038 cost = 1.475951254\n",
      "Epoch: 0039 cost = 1.464239359\n",
      "Epoch: 0040 cost = 1.445980787\n",
      "Epoch: 0041 cost = 1.434831202\n",
      "Epoch: 0042 cost = 1.419658482\n",
      "Epoch: 0043 cost = 1.412607670\n",
      "Epoch: 0044 cost = 1.401449978\n",
      "Epoch: 0045 cost = 1.388388693\n",
      "Epoch: 0046 cost = 1.376820087\n",
      "Epoch: 0047 cost = 1.363971949\n",
      "Epoch: 0048 cost = 1.355172038\n",
      "Epoch: 0049 cost = 1.344074070\n",
      "Epoch: 0050 cost = 1.333901465\n",
      "Epoch: 0051 cost = 1.328725398\n",
      "Epoch: 0052 cost = 1.320026815\n",
      "Epoch: 0053 cost = 1.307588935\n",
      "Epoch: 0054 cost = 1.297336400\n",
      "Epoch: 0055 cost = 1.289697230\n",
      "Epoch: 0056 cost = 1.281832516\n",
      "Epoch: 0057 cost = 1.272499323\n",
      "Epoch: 0058 cost = 1.258755624\n",
      "Epoch: 0059 cost = 1.252810061\n",
      "Epoch: 0060 cost = 1.238868415\n",
      "Epoch: 0061 cost = 1.230094731\n",
      "Epoch: 0062 cost = 1.212265193\n",
      "Epoch: 0063 cost = 1.205418408\n",
      "Epoch: 0064 cost = 1.202143133\n",
      "Epoch: 0065 cost = 1.191200554\n",
      "Epoch: 0066 cost = 1.181502402\n",
      "Epoch: 0067 cost = 1.170481980\n",
      "Epoch: 0068 cost = 1.166195869\n",
      "Epoch: 0069 cost = 1.152277589\n",
      "Epoch: 0070 cost = 1.144442022\n",
      "Epoch: 0071 cost = 1.140480161\n",
      "Epoch: 0072 cost = 1.136446118\n",
      "Epoch: 0073 cost = 1.123020172\n",
      "Epoch: 0074 cost = 1.118529916\n",
      "Epoch: 0075 cost = 1.110975683\n",
      "Epoch: 0076 cost = 1.102402091\n",
      "Epoch: 0077 cost = 1.098445415\n",
      "Epoch: 0078 cost = 1.093311608\n",
      "Epoch: 0079 cost = 1.081785500\n",
      "Epoch: 0080 cost = 1.079454124\n",
      "Epoch: 0081 cost = 1.072496653\n",
      "Epoch: 0082 cost = 1.066497743\n",
      "Epoch: 0083 cost = 1.059523523\n",
      "Epoch: 0084 cost = 1.054698944\n",
      "Epoch: 0085 cost = 1.043922901\n",
      "Epoch: 0086 cost = 1.042980850\n",
      "Epoch: 0087 cost = 1.037008226\n",
      "Epoch: 0088 cost = 1.029981315\n",
      "Epoch: 0089 cost = 1.025008082\n",
      "Epoch: 0090 cost = 1.016887546\n",
      "Epoch: 0091 cost = 1.014941871\n",
      "Epoch: 0092 cost = 1.007415473\n",
      "Epoch: 0093 cost = 0.999279737\n",
      "Epoch: 0094 cost = 0.995621979\n",
      "Epoch: 0095 cost = 0.989194810\n",
      "Epoch: 0096 cost = 0.983939290\n",
      "Epoch: 0097 cost = 0.974210262\n",
      "Epoch: 0098 cost = 0.976161063\n",
      "Epoch: 0099 cost = 0.967984617\n",
      "Accuracy:  0.6934018\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "##################  화자인식 NN 버전 ##################\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = np.load(\"./data.npy\",allow_pickle=True)\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "Y_train = np.array(Y_train, dtype=np.float32)\n",
    "Y_test = np.array(Y_test, dtype=np.float32)\n",
    "\n",
    "X_train = X_train.astype(\"float\")\n",
    "X_test = X_test.astype(\"float\")\n",
    "\n",
    "tf.reset_default_graph() \n",
    "tf.set_random_seed(777)\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "sd = 1 / np.sqrt(13) # standard deviation 표준편차(표본표준편차라 1/root(n))\n",
    "\n",
    "#mfcc의 기본은 20\n",
    "# 20ms일 때216은 각 mfcc feature의 열이 216\n",
    "X = tf.placeholder(tf.float32, [None, 13])\n",
    "# \n",
    "Y = tf.placeholder(tf.float32, [None, tf_classes])\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([216, 200]))\n",
    "# b = tf.Variable(tf.random_normal([200]))\n",
    "\n",
    "#1차 히든레이어\n",
    "W1 = tf.get_variable(\"w1\",\n",
    "    #tf.random_normal([216, 180], mean=0, stddev=sd),\n",
    "        shape=[13, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256], mean=0, stddev=sd), name=\"b1\")\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1) # 1차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "# 2차 히든 레이어\n",
    "W2 = tf.get_variable(\"w2\",\n",
    "    #tf.random_normal([180, 150], mean=0, stddev=sd),\n",
    "         shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256], mean=0, stddev=sd), name=\"b2\")\n",
    "L2 = tf.nn.tanh(tf.matmul(L1, W2) + b2) # 2차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "# 3차 히든 레이어\n",
    "W3 = tf.get_variable(\"w3\",\n",
    "    #tf.random_normal([150, 100], mean=0, stddev=sd),\n",
    "            shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([256], mean=0, stddev=sd), name=\"b3\")\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3) # 3차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "# 4차 히든 레이어\n",
    "W4 = tf.get_variable(\"w4\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[256, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b4\")\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4) # 4차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "# 5차 히든 레이어\n",
    "W5 = tf.get_variable(\"w5\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[128, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b5\")\n",
    "L5 = tf.nn.relu(tf.matmul(L4, W5) + b5) # 5차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L5 = tf.nn.dropout(L5, keep_prob = keep_prob)\n",
    "\n",
    "# 6차 히든 레이어\n",
    "W6 = tf.get_variable(\"w6\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[128, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b6\")\n",
    "L6 = tf.nn.relu(tf.matmul(L5, W6) + b6) # 6차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L6 = tf.nn.dropout(L6, keep_prob = keep_prob)\n",
    "\n",
    "# 7차 히든 레이어\n",
    "W7 = tf.get_variable(\"w7\",\n",
    "    #tf.random_normal([100, 50], mean=0, stddev=sd),\n",
    "             shape=[128, 128],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random_normal([128], mean=0, stddev=sd), name=\"b7\")\n",
    "L7 = tf.nn.relu(tf.matmul(L6, W7) + b7) # 7차 히든레이어는 'Relu' 함수를 쓴다.\n",
    "L7 = tf.nn.dropout(L7, keep_prob = keep_prob)\n",
    "\n",
    "# 최종 레이어\n",
    "W8 = tf.get_variable(\"w8\", \n",
    "    #tf.random_normal([50, tf_classes], mean=0, stddev=sd),\n",
    "            shape=[128, tf_classes],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b8 = tf.Variable(tf.random_normal([tf_classes], mean=0, stddev=sd), name=\"b8\")\n",
    "hypothesis = tf.matmul(L7, W8) + b8\n",
    "\n",
    "\n",
    "\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "\n",
    "batch_size=1\n",
    "x_len = len(X_train)\n",
    "#짝수\n",
    "if(x_len%2==0):\n",
    "    batch_size = 2\n",
    "elif(x_len%3==0):\n",
    "    batch_size = 3\n",
    "elif(x_len%4==0):\n",
    "    batch_size = 4\n",
    "else:\n",
    "    batch_size = 1\n",
    "\n",
    "split_X = np.split(X_train,batch_size)\n",
    "split_Y = np.split(Y_train,batch_size)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(batch_size):\n",
    "        batch_xs = split_X[i]\n",
    "        batch_ys = split_Y[i]\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / batch_size\n",
    "        #if(epoch%10==0):\n",
    "    print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    },
    "colab_type": "code",
    "id": "nQi-62tfROkv",
    "outputId": "30f9cfa2-0d93-48ce-bc09-6248e4ff6b9c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 cost = 0.964903921\n",
      "Epoch: 0001 cost = 0.958195776\n",
      "Epoch: 0002 cost = 0.952903807\n",
      "Epoch: 0003 cost = 0.948287517\n",
      "Epoch: 0004 cost = 0.944144726\n",
      "Epoch: 0005 cost = 0.939996183\n",
      "Epoch: 0006 cost = 0.933325410\n",
      "Epoch: 0007 cost = 0.931025058\n",
      "Epoch: 0008 cost = 0.930456817\n",
      "Epoch: 0009 cost = 0.923125982\n",
      "Epoch: 0010 cost = 0.917876691\n",
      "Epoch: 0011 cost = 0.908817828\n",
      "Epoch: 0012 cost = 0.909423292\n",
      "Epoch: 0013 cost = 0.906035393\n",
      "Epoch: 0014 cost = 0.897664726\n",
      "Epoch: 0015 cost = 0.897794008\n",
      "Epoch: 0016 cost = 0.888653934\n",
      "Epoch: 0017 cost = 0.888538957\n",
      "Epoch: 0018 cost = 0.880851656\n",
      "Epoch: 0019 cost = 0.874591172\n",
      "Epoch: 0020 cost = 0.874686152\n",
      "Epoch: 0021 cost = 0.868501544\n",
      "Epoch: 0022 cost = 0.866418779\n",
      "Epoch: 0023 cost = 0.864553511\n",
      "Epoch: 0024 cost = 0.859253049\n",
      "Epoch: 0025 cost = 0.854415625\n",
      "Epoch: 0026 cost = 0.850166768\n",
      "Epoch: 0027 cost = 0.847719997\n",
      "Epoch: 0028 cost = 0.844735593\n",
      "Epoch: 0029 cost = 0.838407159\n",
      "Epoch: 0030 cost = 0.835407972\n",
      "Epoch: 0031 cost = 0.833742559\n",
      "Epoch: 0032 cost = 0.826465011\n",
      "Epoch: 0033 cost = 0.823077768\n",
      "Epoch: 0034 cost = 0.825568020\n",
      "Epoch: 0035 cost = 0.816743642\n",
      "Epoch: 0036 cost = 0.822203189\n",
      "Epoch: 0037 cost = 0.811628640\n",
      "Epoch: 0038 cost = 0.806453347\n",
      "Epoch: 0039 cost = 0.803167105\n",
      "Epoch: 0040 cost = 0.804996848\n",
      "Epoch: 0041 cost = 0.803255945\n",
      "Epoch: 0042 cost = 0.800399512\n",
      "Epoch: 0043 cost = 0.795410484\n",
      "Epoch: 0044 cost = 0.792761326\n",
      "Epoch: 0045 cost = 0.789864749\n",
      "Epoch: 0046 cost = 0.788827062\n",
      "Epoch: 0047 cost = 0.786981136\n",
      "Epoch: 0048 cost = 0.781900436\n",
      "Epoch: 0049 cost = 0.771944314\n",
      "Epoch: 0050 cost = 0.777235806\n",
      "Epoch: 0051 cost = 0.771283537\n",
      "Epoch: 0052 cost = 0.768956244\n",
      "Epoch: 0053 cost = 0.771292716\n",
      "Epoch: 0054 cost = 0.765926063\n",
      "Epoch: 0055 cost = 0.765517086\n",
      "Epoch: 0056 cost = 0.769478530\n",
      "Epoch: 0057 cost = 0.761544108\n",
      "Epoch: 0058 cost = 0.760033667\n",
      "Epoch: 0059 cost = 0.758405417\n",
      "Epoch: 0060 cost = 0.753073782\n",
      "Epoch: 0061 cost = 0.749439001\n",
      "Epoch: 0062 cost = 0.750976503\n",
      "Epoch: 0063 cost = 0.749595702\n",
      "Epoch: 0064 cost = 0.744705796\n",
      "Epoch: 0065 cost = 0.742092073\n"
     ]
    }
   ],
   "source": [
    "#학습만 반복 코스트 보며 설정\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(batch_size):\n",
    "        batch_xs = split_X[i]\n",
    "        batch_ys = split_Y[i]\n",
    "        feed_dict = {X:batch_xs, Y:batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / batch_size\n",
    "        #if(epoch%10==0):\n",
    "    print('Epoch:', '%04d' % (epoch), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n",
    "\n",
    "print('Learning Finished!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "colab_type": "code",
    "id": "pCnSi3TyROky",
    "outputId": "6ec355c7-f356-47d5-aec6-95a437d13bee"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './my_voice_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215.0
    },
    "colab_type": "code",
    "id": "xAUmFVmEROk0",
    "outputId": "75d97241-425b-4cd6-a3f5-1e26fa550e93"
   },
   "outputs": [],
   "source": [
    "y, sr = librosa.load(os.path.join(\"./test_청하.wav\"))\n",
    "\n",
    "X_test = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "'''\n",
    "0 유인나\n",
    "1 배철수\n",
    "2 이재은\n",
    "3 최일구\n",
    "4 문재인 대통령\n",
    "5 청하\n",
    "'''\n",
    "label = [0 for i in range(tf_classes)] #class가 3개이니까 y_test만드는 과정\n",
    "label[2] = 1\n",
    "Y_test = []\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    Y_test.append(label)\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(Y_test))\n",
    "\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"predict\")\n",
    "print(pd.value_counts(pd.Series(sess.run(tf.argmax(hypothesis, 1),\n",
    "                                    feed_dict={X: X_test, keep_prob:1}))))\n",
    "print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: X_test, Y:Y_test, keep_prob:1}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yilG8jtX9ZCO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "화자인식.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pjt",
   "language": "python",
   "name": "pjt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
